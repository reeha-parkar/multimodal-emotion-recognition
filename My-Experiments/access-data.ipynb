{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c3ff4f",
   "metadata": {},
   "source": [
    "Connect to jupyter kernel of KCL HPC Create\n",
    "\n",
    "And cd to the Tutorials directory, that's where the data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8a6d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cephfs/volumes/hpc_data_usr/k24083007/2070c87e-fe07-4f03-a6c4-cae0de8ce617/cmu-mosei-experiments/CMU-MultimodalSDK-Tutorials\n"
     ]
    }
   ],
   "source": [
    "%cd cmu-mosei-experiments/CMU-MultimodalSDK-Tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583be278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "from constants.paths import SDK_PATH, DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad83339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 26 19:26:59 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c8d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data files:\n",
      "CMU_MOSEI_COVAREP.csd\n",
      "CMU_MOSEI_TimestampedWords.csd\n",
      "CMU_MOSEI_OpenFace2.csd\n",
      "CMU_MOSEI_VisualFacet42.csd\n",
      "CMU_MOSEI_TimestampedWordVectors.csd\n",
      "CMU_MOSEI_TimestampedPhones.csd\n",
      "CMU_MOSEI_Labels.csd\n"
     ]
    }
   ],
   "source": [
    "# Ensure SDK is in path\n",
    "sys.path.append(SDK_PATH)\n",
    "\n",
    "# Make sure DATA_PATH exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"Error: DATA_PATH does not exist: {DATA_PATH}\")\n",
    "    print(\"Please modify DATA_PATH to point to your .csd files directory\")\n",
    "    # os.makedirs(DATA_PATH, exist_ok=True)\n",
    "else:\n",
    "    data_files = os.listdir(DATA_PATH)\n",
    "    print(\"Available data files:\")\n",
    "    print('\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38628bd7",
   "metadata": {},
   "source": [
    "### Viewing the features\n",
    "Loading the multimodal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ba986e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 18:47:39.518] | Success | \u001b[0mComputational sequence read from file ./data/CMU_MOSEI_TimestampedWords.csd ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:47:39.589] | Status  | \u001b[0mChecking the integrity of the <words> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:47:39.589] | Status  | \u001b[0mChecking the format of the data in <words> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 18:47:40.561] | Success | \u001b[0m<words> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:47:40.561] | Status  | \u001b[0mChecking the format of the metadata in <words> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 18:47:40.561] | Warning | \u001b[0m<words> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2025-06-26 18:47:40.625] | Success | \u001b[0mComputational sequence read from file ./data/CMU_MOSEI_VisualFacet42.csd ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:48:20.628] | Status  | \u001b[0mChecking the integrity of the <FACET 4.2> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:48:20.628] | Status  | \u001b[0mChecking the format of the data in <FACET 4.2> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 18:48:21.692] | Success | \u001b[0m<FACET 4.2> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:48:21.692] | Status  | \u001b[0mChecking the format of the metadata in <FACET 4.2> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 18:48:21.692] | Warning | \u001b[0m<FACET 4.2> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2025-06-26 18:48:21.753] | Success | \u001b[0mComputational sequence read from file ./data/CMU_MOSEI_COVAREP.csd ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:51:27.417] | Status  | \u001b[0mChecking the integrity of the <COVAREP> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:51:27.417] | Status  | \u001b[0mChecking the format of the data in <COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 18:51:59.119] | Success | \u001b[0m<COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:51:59.120] | Status  | \u001b[0mChecking the format of the metadata in <COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 18:51:59.120] | Warning | \u001b[0m<COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2025-06-26 18:51:59.120] | Success | \u001b[0mDataset initialized successfully ... \n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "text_field = 'CMU_MOSEI_TimestampedWords'\n",
    "visual_field = 'CMU_MOSEI_VisualFacet42'\n",
    "acoustic_field = 'CMU_MOSEI_COVAREP'\n",
    "\n",
    "# Define the features to load\n",
    "features = [\n",
    "    text_field, \n",
    "    visual_field, \n",
    "    acoustic_field\n",
    "]\n",
    "\n",
    "recipe = {feat: os.path.join(DATA_PATH, feat) + '.csd' for feat in features}\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    dataset = md.mmdataset(recipe)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Available files:\", data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "757d17af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: ['CMU_MOSEI_TimestampedWords', 'CMU_MOSEI_VisualFacet42', 'CMU_MOSEI_COVAREP']\n",
      "================================================================================\n",
      "Number of videos: 3837\n",
      "First 10 video IDs: ['--qXJuDtHPw', '-3g5yACwYnA', '-3nNcZdcdvU', '-571d8cVauQ', '-6rXp3zJ3kc', '-9YyBTjo1zo', '-9y-fZ3swSY', '-AUZQgSxyPQ', '-Alixo7euuU', '-Eqdz5y4pEY']\n",
      "================================================================================\n",
      "Examining video: -IqSFQePnpU\n",
      "Available data for this video: ['features', 'intervals']\n",
      "================================================================================\n",
      "Visual features shape: (3658, 35)\n",
      "Visual intervals shape: (3658, 2)\n",
      "Text features shape: (321, 1)\n",
      "Acoustic features shape: (12209, 74)\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset structure\n",
    "print(\"Dataset keys:\", list(dataset.keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get video IDs from one modality\n",
    "video_ids = list(dataset[visual_field].keys())\n",
    "print(f\"Number of videos: {len(video_ids)}\")\n",
    "print(\"First 10 video IDs:\", video_ids[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Examine a specific video\n",
    "some_id = video_ids[15] if len(video_ids) > 15 else video_ids[0]\n",
    "print(f\"Examining video: {some_id}\")\n",
    "print(\"Available data for this video:\", list(dataset[visual_field][some_id].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check shapes of different modalities for this video\n",
    "print(\"Visual features shape:\", dataset[visual_field][some_id]['features'].shape)\n",
    "print(\"Visual intervals shape:\", dataset[visual_field][some_id]['intervals'].shape)\n",
    "print(\"Text features shape:\", dataset[text_field][some_id]['features'].shape)\n",
    "print(\"Acoustic features shape:\", dataset[acoustic_field][some_id]['features'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e545c4c",
   "metadata": {},
   "source": [
    "Different modalities have different number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c76dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning modalities to text...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:54:03.875] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 18:54:03.878] | Warning | \u001b[0mPEBwwe0PLZ8 entry is not shared among all sequences, removing it ...\n",
      "\u001b[92m\u001b[1m[2025-06-26 18:54:03.881] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:54:03.881] | Status  | \u001b[0mPre-alignment based on <CMU_MOSEI_TimestampedWords> computational sequence started ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:54:19.987] | Status  | \u001b[0mPre-alignment done for <CMU_MOSEI_VisualFacet42> ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:56:20.207] | Status  | \u001b[0mPre-alignment done for <CMU_MOSEI_COVAREP> ...\n",
      "\u001b[94m\u001b[1m[2025-06-26 18:56:20.878] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 19:31:02.359] | Success | \u001b[0mAlignment to <CMU_MOSEI_TimestampedWords> complete.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:02.359] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2025-06-26 19:31:02.444] | Success | \u001b[0mInitialized empty <CMU_MOSEI_TimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:02.445] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSEI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 19:31:04.335] | Success | \u001b[0m<CMU_MOSEI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:04.366] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSEI_TimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 19:31:04.368] | Warning | \u001b[0m<CMU_MOSEI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2025-06-26 19:31:04.372] | Success | \u001b[0mInitialized empty <CMU_MOSEI_VisualFacet42> computational sequence.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:04.434] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSEI_VisualFacet42> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 19:31:06.034] | Success | \u001b[0m<CMU_MOSEI_VisualFacet42> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:06.034] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSEI_VisualFacet42> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 19:31:06.034] | Warning | \u001b[0m<CMU_MOSEI_VisualFacet42> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2025-06-26 19:31:06.034] | Success | \u001b[0mInitialized empty <CMU_MOSEI_COVAREP> computational sequence.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:06.034] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSEI_COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2025-06-26 19:31:07.413] | Success | \u001b[0m<CMU_MOSEI_COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2025-06-26 19:31:07.414] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSEI_COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2025-06-26 19:31:07.414] | Warning | \u001b[0m<CMU_MOSEI_COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "Alignment completed!\n"
     ]
    }
   ],
   "source": [
    "# Align the modalities (following the tutorial approach)\n",
    "def avg(intervals: np.array, features: np.array) -> np.array:\n",
    "    \"\"\"Simple averaging function that does not depend on intervals\"\"\"\n",
    "    try:\n",
    "        return np.average(features, axis=0)\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "# Align to words with averaging\n",
    "print(\"Aligning modalities to text...\")\n",
    "dataset.align(text_field, collapse_functions=[avg])\n",
    "print(\"Alignment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels and align to them\n",
    "label_field = 'CMU_MOSEI_Labels'\n",
    "\n",
    "# Add labels to the dataset\n",
    "label_recipe = {label_field: os.path.join(DATA_PATH, label_field + '.csd')}\n",
    "dataset.add_computational_sequences(label_recipe, destination=None)\n",
    "\n",
    "# Align to labels to get labeled segments\n",
    "dataset.align(label_field)\n",
    "\n",
    "# Check the new keys format\n",
    "new_keys = list(dataset[text_field].keys())\n",
    "print(f\"After alignment, keys changed to format: {new_keys[55]}\")\n",
    "print(f\"Total number of segments: {len(new_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0269597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the data statistics\n",
    "print(\"=== DATA ANALYSIS ===\")\n",
    "\n",
    "# Count segments per modality\n",
    "text_segments = len(list(dataset[text_field].keys()))\n",
    "visual_segments = len(list(dataset[visual_field].keys()))\n",
    "acoustic_segments = len(list(dataset[acoustic_field].keys()))\n",
    "label_segments = len(list(dataset[label_field].keys()))\n",
    "\n",
    "print(f\"Text segments: {text_segments}\")\n",
    "print(f\"Visual segments: {visual_segments}\")\n",
    "print(f\"Acoustic segments: {acoustic_segments}\")\n",
    "print(f\"Label segments: {label_segments}\")\n",
    "\n",
    "# Sample a few segments to check data\n",
    "sample_segments = list(dataset[label_field].keys())[:5]\n",
    "for segment in sample_segments:\n",
    "    try:\n",
    "        text_shape = dataset[text_field][segment]['features'].shape\n",
    "        visual_shape = dataset[visual_field][segment]['features'].shape\n",
    "        acoustic_shape = dataset[acoustic_field][segment]['features'].shape\n",
    "        label_shape = dataset[label_field][segment]['features'].shape\n",
    "        \n",
    "        print(f\"\\nSegment: {segment}\")\n",
    "        print(f\"  Text: {text_shape}, Visual: {visual_shape}, Acoustic: {acoustic_shape}, Label: {label_shape}\")\n",
    "        print(f\"  Label value: {dataset[label_field][segment]['features']}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing data for segment {segment}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76bf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65e07039",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "\n",
    "Based on the attached image, here's the markdown-displayable directory structure:\n",
    "\n",
    "```\n",
    "cmu-mosei-experiments/\n",
    "├── .ipynb_checkpoints/\n",
    "├── CMU-MultimodalSDK/\n",
    "├── CMU-MultimodalSDK-Tutorials/\n",
    "│   ├── .ipynb_checkpoints/\n",
    "│   ├── constants/\n",
    "│   └── data/\n",
    "│       ├── CMU_MOSEI_COVAREP.csd\n",
    "│       ├── CMU_MOSEI_Labels.csd\n",
    "│       ├── CMU_MOSEI_OpenFace2.csd\n",
    "│       ├── CMU_MOSEI_TimestampedPhones.csd\n",
    "│       ├── CMU_MOSEI_TimestampedWords.csd\n",
    "│       ├── CMU_MOSEI_TimestampedWordVectors.csd\n",
    "│       └── CMU_MOSEI_VisualFacet42.csd\n",
    "├── debug_mmsdk.py\n",
    "├── README.md\n",
    "├── text_LSTM.py\n",
    "└── tutorial_interactive.ipynb\n",
    "```\n",
    "\n",
    "### Description of Key Components:\n",
    "\n",
    "- **data/**: Contains the CMU-MOSEI dataset files in `.csd` format\n",
    "  - `CMU_MOSEI_COVAREP.csd`: Acoustic features\n",
    "  - `CMU_MOSEI_Labels.csd`: Emotion labels and annotations\n",
    "  - `CMU_MOSEI_OpenFace2.csd`: Visual facial features\n",
    "  - `CMU_MOSEI_TimestampedPhones.csd`: Phone-level timestamps\n",
    "  - `CMU_MOSEI_TimestampedWords.csd`: Word-level text features\n",
    "  - `CMU_MOSEI_TimestampedWordVectors.csd`: Word vector embeddings\n",
    "  - `CMU_MOSEI_VisualFacet42.csd`: 42-dimensional visual features\n",
    "\n",
    "- **constants/**: Configuration and path constants\n",
    "- **CMU-MultimodalSDK/**: Core SDK for multimodal data processing\n",
    "- **CMU-MultimodalSDK-Tutorials/**: Tutorial notebooks and examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jvenv)",
   "language": "python",
   "name": "jvenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
